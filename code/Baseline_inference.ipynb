{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages (from scikit-learn) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp313-cp313-macosx_12_0_arm64.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m30.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 18964,
     "status": "ok",
     "timestamp": 1751331464553,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "v3-cuIDjgNm-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1751331747281,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "f7VLmR-wgRf1"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(outputs, labels):\n",
    "    matches = sum(p == y for p, y in zip(outputs, labels))\n",
    "    total = len(labels)\n",
    "    return matches / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18648,
     "status": "ok",
     "timestamp": 1751331485456,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "BsQ7_J0Lqwhr",
    "outputId": "69c218d0-8012-4794-bb8d-503783fb98b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2590,
     "status": "ok",
     "timestamp": 1751331488042,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "cD9hTCimq1MN",
    "outputId": "8b929f74-479f-40e2-8236-0bd9192dd3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/Intern_summer2025/code\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/Intern_summer2025/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15510,
     "status": "ok",
     "timestamp": 1751331503553,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "cJRT-vnzq2HN"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('../../data/dataset.csv')\n",
    "# dataset = pd.read_csv('../../data/prompts-instruct-model.csv')\n",
    "dataset = pd.read_csv('../../data/dataset2_sin_os_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751331503572,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "ztdAMVjPrikE",
    "outputId": "d5413d4e-ad5a-4b16-bc44-352e2b7e0ba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713310, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter ([A], [B], [C], or [D]).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Age of the patient: 68.0\n",
      " * HER2 status: No\n",
      " * MSI Type: Indeterminate\n",
      " * Overal Survival Status: 0:LIVING\n",
      " * Cancer stage: Stage 1-3\n",
      " * Smoking history: Former/Current Smoker\n",
      " * Fraction Genome altered: 0.3146\n",
      " * History of PDL-1: No\n",
      " * Number of tumor diagnoses (ICD-O codes): 2\n",
      " * Mutation Count: 1.0\n",
      " * Gender: Female\n",
      " * Mutations history: PIK3C2G, FLT4, PIK3R3, BLM, MAP3K1, CCNE1, ATR, BRIP1, TSHR, SDHA, RET, PTPRD, FBXW7, NSD1, PDGFRA, AXIN2, TP53, SMARCA4, PTPRT, HGF, DOT1L, KDM5A, PTPRS, CREBBP, KMT2C, ATRX\n",
      " * Treatment history: CISPLATIN, ETOPOSIDE, CARBOPLATIN, INVESTIGATIONAL, INVESTIGATIONAL, NIVOLUMAB\n",
      "Question: \"Where did the cancer spread to, affecting the patient's health and treatment options?\"\n",
      "Options (choose ONLY one option letter): \n",
      " [A]: Adrenal Glands, Bone, Intra Abdominal, Lung, Lymph Nodes\n",
      " [B]: Bone, Intra Abdominal, Liver, Lung, Lymph Nodes\n",
      " [C]: Intra Abdominal, Lung, Lymph Nodes\n",
      " [D]: Liver, Pleura\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:1].prompt.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsXYrb0Orze8"
   },
   "source": [
    "There are 23777 patients in the dataset. We created 5 versions of a prompt per variable(7) for each patient. So 23777 x 5 x7 = 832195. That's 35 prompts per patient id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1751331507172,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "56UJzwterkjy",
    "outputId": "04b6a751-b5b2-4b8e-bc58-2ad191a5ebf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PATIENT_ID    0\n",
       "variable      0\n",
       "prompt        0\n",
       "answer        0\n",
       "replicate     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgc5mYMftfyI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Split by unique patients 80/10/10\n",
    "\n",
    "no patient appears in more than one of the training, validation, or test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1751331509275,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "l9rIJeWMsW6F",
    "outputId": "d095c11c-1d34-47a0-ecce-338c620450d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>variable</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>replicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P-0000012</td>\n",
       "      <td>METASTATIC_SITES</td>\n",
       "      <td>Instruction: You are a helpful medical assista...</td>\n",
       "      <td>[C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P-0000012</td>\n",
       "      <td>OS_MONTHS</td>\n",
       "      <td>Instruction: You are a helpful medical assista...</td>\n",
       "      <td>[C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P-0000012</td>\n",
       "      <td>CANCER_TYPE</td>\n",
       "      <td>Instruction: You are a helpful medical assista...</td>\n",
       "      <td>[B]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P-0000012</td>\n",
       "      <td>TMB_nonsynonymous</td>\n",
       "      <td>Instruction: You are a helpful medical assista...</td>\n",
       "      <td>[D]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P-0000012</td>\n",
       "      <td>Tumor_Purity</td>\n",
       "      <td>Instruction: You are a helpful medical assista...</td>\n",
       "      <td>[A]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PATIENT_ID           variable  \\\n",
       "0  P-0000012   METASTATIC_SITES   \n",
       "1  P-0000012          OS_MONTHS   \n",
       "2  P-0000012        CANCER_TYPE   \n",
       "3  P-0000012  TMB_nonsynonymous   \n",
       "4  P-0000012       Tumor_Purity   \n",
       "\n",
       "                                              prompt answer  replicate  \n",
       "0  Instruction: You are a helpful medical assista...    [C]          0  \n",
       "1  Instruction: You are a helpful medical assista...    [C]          0  \n",
       "2  Instruction: You are a helpful medical assista...    [B]          0  \n",
       "3  Instruction: You are a helpful medical assista...    [D]          0  \n",
       "4  Instruction: You are a helpful medical assista...    [A]          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1751331511447,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "h70tPf3HuyFO"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Get unique patient IDs\n",
    "unique_patients = dataset['PATIENT_ID'].unique()\n",
    "\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "#Split into train (80%), temp (20%)\n",
    "train_patients, temp_patients = train_test_split(\n",
    "    unique_patients,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Split temp into validation (10%) and test (10%)\n",
    "val_patients, test_patients = train_test_split(\n",
    "    temp_patients,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Create splits based on patient IDs\n",
    "train_df = dataset[dataset['PATIENT_ID'].isin(train_patients)].copy()\n",
    "val_df   = dataset[dataset['PATIENT_ID'].isin(val_patients)].copy()\n",
    "test_df  = dataset[dataset['PATIENT_ID'].isin(test_patients)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751331513181,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "Dn_oQacoxqsH",
    "outputId": "ae97f58c-a1ab-4e27-ef3e-61c09178b21b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((570630, 5), (71340, 5), (71340, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751331514254,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "5IFtFkHn8iQW"
   },
   "outputs": [],
   "source": [
    "X_train = train_df['prompt']\n",
    "y_train = train_df['answer']\n",
    "X_val = val_df['prompt']\n",
    "y_val = val_df['answer']\n",
    "X_test = test_df['prompt']\n",
    "y_test = test_df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8513,
     "status": "ok",
     "timestamp": 1751331524753,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "GNPLAFK-bW0R"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#To save datasets\n",
    "datasets = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_val': X_val,\n",
    "    'y_val': y_val,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "}\n",
    "\n",
    "pickle.dump(datasets, open('../../data/dataset-Prompts/datasets.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= pickle.load(open('../../data/dataset-Prompts/datasets.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = datasets['X_val']\n",
    "y_val = datasets['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1751331534242,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "6mAzMz8Kxuox",
    "outputId": "2e6d05f8-164b-4ed4-8da8-531ae7f8860d"
   },
   "outputs": [],
   "source": [
    "# Device setting\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "device =  'mps'\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1939,
     "status": "ok",
     "timestamp": 1751331538029,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "o7zFMCD75ADK",
    "outputId": "595549a6-d364-49d1-9f33-1d47fd70a150"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# token = userdata.get(\"HF_TOKEN\")\n",
    "# login(token=token)\n",
    "# !huggingface-cli whoami\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaxmhY8I9iIc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Infererence with Llama model: meta-llama/Llama-3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "88a5222bc7444312b1f1a56c76fe1bec",
      "876ed0f3244f4ee6aec97dea09941cce",
      "78405dbff41e46a6ad9541228c2035fe",
      "8bdec4c7248d43258864f7f4fd691f36",
      "1a31e3dda0c84a5f90cec66ccba14a82",
      "d5e50f61d2024c09a6dff1c778c0c95b",
      "67bef14fa2e84f3b837e5787d151c3c5",
      "7379fe55ed244828ba6cc895220d4f09",
      "bdc2bc1767f8402b8f8148e7bc4467e8",
      "3025a7a3bc0641fe9d82b1787c35669f",
      "6e404feda7f04b8391ffe6fcd6d97f92",
      "4d00428af1f843599c9f8f284189f416",
      "bbe62fd9f89647858f5b4cc95fa467a6",
      "3baa5548f46f4e94a5a0910cc7d6e17f",
      "cec2105aaa2e41cbaff01045e553cbd2",
      "ed5f40d0db704f6e9fb89028cd5f325a",
      "8485e8a28f264e12a282d09577e421e6",
      "72f84c8e08c04094a2b27cf938ecad4d",
      "6e74c67a009648d0b70d5b0cb18a4d4c",
      "f3ebbb828cbd484696f39de4d62a0843",
      "b420185cfaba440d9f7f3f87d9819237",
      "9e1e47436c4d4db39f1de0d93a70c256",
      "de2c365f404f40d0914b32b0a70a3ff9",
      "10b5949425654b49ad3d08539550ad28",
      "8b07f1caca2949668734b419b8a6c945",
      "80e8618a393c447596704f74e1c2ca23",
      "ae5b6f2f15754660b12dc9fd9d7ddf88",
      "efd14e972616417ca3b06cd40b8606de",
      "449f3e5a5b0e4ef2b4cd9e7e68b1eafa",
      "ca585ec7b4a94176b20d4bd0ce044a4d",
      "0b35977e47de46abb1d4b0e15223dd0d",
      "9612d26ad3d145cd8bcc08a5a3859914",
      "492b5f09429a466ea8c7e7d2e7ce8693",
      "69f90315a47c4c859dd3b1ba13a63482",
      "adbf90264e114f8a8d2a68b7b22dff28",
      "4d8665ef790f4afba981f2344a82e3f1",
      "10ec2adc23af474ca9880c4f0c09ce75",
      "ec6335de6cff41e2a316093a54c96f7a",
      "c7ea70e72e7a449eaeec4133c5ef2b40",
      "e2bb8e01b4fd440c89ad6bb975392afe",
      "43fab6d9e1fb43ed9b6fc27deac10a52",
      "14684c09fa9248a6acad9e1abdf844f8",
      "0088ee3ff026403eb87fa3d85bcc0d46",
      "53931ab3cea84233b9da2deae18e498a",
      "4875446e019e45ab9458f92c393c6374",
      "e3435f4c90f14c808b57ed74e50908d2",
      "63f0fc7942124b68b82acb9683c0c820",
      "579b355e3c8e43609f7bcaf03a2a179e",
      "d9404c11710442388654b71cd506803d",
      "c08eabcc5a5f46e5b667917a48ce925b",
      "48a602a4bbfd497cb44daf3d5e7ec45e",
      "303bb2ef644446bdb0d042a942521acb",
      "b6147fd0fe2c44c085d7850b28313ecd",
      "72c3a5e1a1d54496acc73ded71117e69",
      "202eb6aadec746dda0f09abf4e52260d",
      "d8ec60aee5684d81a250fefcc8be0745",
      "c8ad1a52c0f14017b2b170337024fb0a",
      "623c81a441384000b60f70d8c1a0a795",
      "cdb4979630224e6ba3d4411f0f8d32dd",
      "a86d675647714cb794e9be32e240b4f7",
      "497af44c69ac4c44bc4903f51edf59ad",
      "75d615e176aa46b5a5bedf2dc48da75a",
      "4cecfabca8534e2cb7708986ab526c4a",
      "2ab1c31382ba405eb5473b390d5b61d2",
      "e0e7eb30cb3745ab907ce0b9425aa469",
      "a64ca0bc051e460486eee54477d60e5c"
     ]
    },
    "executionInfo": {
     "elapsed": 110960,
     "status": "ok",
     "timestamp": 1751331650240,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "zkVbWpXd8cMq",
    "outputId": "c4bb2bc0-c60f-4cc9-9f08-313fba7fab38"
   },
   "outputs": [],
   "source": [
    "# Upload model\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-1B\"\n",
    "llama_zero = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "llama_zero.eval()\n",
    "\n",
    "# Upload tokenizer\n",
    "tokenizer_llama = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "tokenizer_llama.pad_token = tokenizer_llama.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751331656799,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "mekz2hWlBitY"
   },
   "outputs": [],
   "source": [
    "#Model inference LLamma-3.2-1B\n",
    "def get_outputs(model, prompts, tokenizer, max_new_tokens=2):\n",
    "    # tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for i in tqdm(prompts, desc=\"Generating answers\"):\n",
    "        tokenized_prompt = tokenizer(i, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=tokenized_prompt['input_ids'],\n",
    "            attention_mask=tokenized_prompt['attention_mask'],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,            # enable sampling\n",
    "            temperature=0.7,           # controls randomness\n",
    "            top_p=0.9,                 # nucleus sampling\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(generated_ids[0][tokenized_prompt['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        # print(f'inicio generated_text : {generated_text} fin')\n",
    "\n",
    "        match = re.search(r'\\b([A-D])\\b', generated_text.strip().upper())\n",
    "        outputs.append(match.group(1) if match else \"X\")\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83230,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321214,
     "status": "ok",
     "timestamp": 1751332159137,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "Iz2IYAUKDBrH",
    "outputId": "c421e4d2-243c-4a76-8050-3acf37e632ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:   4%|██▍                                                       | 3514/83230 [08:44<3:09:46,  7.00it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = get_outputs(llama_zero, X_val, tokenizer_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1751332205935,
     "user": {
      "displayName": "Ana Maria Lopez Arciniegas",
      "userId": "04113639144805443026"
     },
     "user_tz": 240
    },
    "id": "qiYHl_8YhPpF",
    "outputId": "ebd90799-150f-4632-8aee-8314f063cf63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24980175417517722"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy(outputs, labels):\n",
    "    matches = sum(p == y for p, y in zip(outputs, labels))\n",
    "    total = len(labels)\n",
    "    return matches / total if total > 0 else 0.0\n",
    "\n",
    "accu = get_accuracy(outputs, y_val)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83230"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Infererence with Llama model: meta-llama/llama3:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed2be41ce24939a05cd8b3501b8cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model ID\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "# Setup device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "dtype = torch.float32  # MPS only supports float32\n",
    "\n",
    "# Load model\n",
    "llama_zero = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=dtype,\n",
    "    device_map={\"\": device}\n",
    ")\n",
    "llama_zero.eval()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer_llama = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "tokenizer_llama.pad_token = tokenizer_llama.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inference LLamma-3-8B\n",
    "def get_outputs(model, prompts, tokenizer, max_new_tokens=2):\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for i in tqdm(prompts, desc=\"Generating answers\"):\n",
    "        tokenized_prompt = tokenizer(i, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=tokenized_prompt['input_ids'],\n",
    "            attention_mask=tokenized_prompt['attention_mask'],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,            # enable sampling\n",
    "            temperature=0.7,           # controls randomness\n",
    "            top_p=0.9,                 # nucleus sampling\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(generated_ids[0][tokenized_prompt['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        print(f'inicio generated_text : {generated_text} fin')\n",
    "\n",
    "        match = re.search(r'\\b([A-D])\\b', generated_text.strip().upper())\n",
    "        outputs.append(match.group(1) if match else \"X\")\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:   5%|███▎                                                              | 1/20 [00:01<00:33,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  C\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  10%|██████▌                                                           | 2/20 [00:02<00:22,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  A\n",
      "\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  15%|█████████▉                                                        | 3/20 [00:03<00:18,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  B\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  20%|█████████████▏                                                    | 4/20 [00:04<00:16,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  A\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  25%|████████████████▌                                                 | 5/20 [00:05<00:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  C\n",
      "\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  30%|███████████████████▊                                              | 6/20 [00:06<00:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  35%|███████████████████████                                           | 7/20 [00:07<00:12,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  D: fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  40%|██████████████████████████▍                                       | 8/20 [00:08<00:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  45%|█████████████████████████████▋                                    | 9/20 [00:08<00:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  C\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  50%|████████████████████████████████▌                                | 10/20 [00:09<00:09,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  B: fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  55%|███████████████████████████████████▊                             | 11/20 [00:10<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  D\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  60%|███████████████████████████████████████                          | 12/20 [00:11<00:07,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  B fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  65%|██████████████████████████████████████████▎                      | 13/20 [00:12<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  70%|█████████████████████████████████████████████▌                   | 14/20 [00:13<00:05,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  B\n",
      "\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  75%|████████████████████████████████████████████████▊                | 15/20 [00:14<00:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  80%|████████████████████████████████████████████████████             | 16/20 [00:15<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  C\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  85%|███████████████████████████████████████████████████████▎         | 17/20 [00:16<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  D: fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  90%|██████████████████████████████████████████████████████████▌      | 18/20 [00:16<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  A\n",
      " fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers:  95%|█████████████████████████████████████████████████████████████▊   | 19/20 [00:18<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  D: fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|█████████████████████████████████████████████████████████████████| 20/20 [00:18<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio generated_text :  A fin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = get_outputs(llama_zero, X_val[:20], tokenizer_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(outputs, labels):\n",
    "    matches = sum(p == y for p, y in zip(outputs, labels))\n",
    "    total = len(labels)\n",
    "    return matches / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = get_accuracy(outputs, y_val[:20])\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt 1 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Gender: Female\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * Smoking history: Unknown\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Fraction Genome altered: 0.3578\n",
      " * MSI Type: Stable\n",
      " * Age of the patient: 34.0\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Mutation Count: 7.0\n",
      " * Cancer stage: Stage 4\n",
      " * History of PDL-1: Not available\n",
      " * HER2 status: Yes\n",
      "Question: \"What are the metastatic sites located in the cancer patient's body?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: Bone, Cns Brain, Intra Abdominal, Liver, Lymph Nodes\n",
      " B: Bone, Cns Brain, Liver, Lung, Lymph Nodes\n",
      " C: Intra Abdominal, Liver, Lymph Nodes, Pleura\n",
      " D: Bone, Lung, Reproductive Organs\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: C\n",
      "\n",
      "\n",
      "--- Prompt 2 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Smoking history: Unknown\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Cancer stage: Stage 4\n",
      " * Mutation Count: 7.0\n",
      " * History of PDL-1: Not available\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * HER2 status: Yes\n",
      " * Gender: Female\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * MSI Type: Stable\n",
      " * Age of the patient: 34.0\n",
      " * Overal Survival Status: 1:DECEASED\n",
      "Question: \"How many months has the patient been surviving with their cancer treatment?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: 12.55889035\n",
      " B: 20.51504601\n",
      " C: 18.11504864\n",
      " D: 63.84650537\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: A\n",
      "\n",
      "\n",
      "--- Prompt 3 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Mutation Count: 7.0\n",
      " * Smoking history: Unknown\n",
      " * History of PDL-1: Not available\n",
      " * Gender: Female\n",
      " * Cancer stage: Stage 4\n",
      " * MSI Type: Stable\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Age of the patient: 34.0\n",
      " * HER2 status: Yes\n",
      " * Overal Survival Status: 1:DECEASED\n",
      "Question: \"What type of cancer was diagnosed in the patient?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: Non-Small Cell Lung Cancer\n",
      " B: Colorectal Cancer\n",
      " C: Pancreatic Cancer\n",
      " D: Breast Cancer\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: B\n",
      "\n",
      "\n",
      "--- Prompt 4 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * MSI Type: Stable\n",
      " * Smoking history: Unknown\n",
      " * HER2 status: Yes\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * Gender: Female\n",
      " * Mutation Count: 7.0\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Age of the patient: 34.0\n",
      " * History of PDL-1: Not available\n",
      " * Cancer stage: Stage 4\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      "Question: What is the tumor mutation burden of non-synonymous mutations in a patient's genes?\n",
      "Options (choose ONLY one option letter): \n",
      " A: 1.72939619\n",
      " B: 1.72939619\n",
      " C: 8.873242405\n",
      " D: 12.97047142\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: A\n",
      "\n",
      "\n",
      "--- Prompt 5 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * MSI Type: Stable\n",
      " * Age of the patient: 34.0\n",
      " * Smoking history: Unknown\n",
      " * History of PDL-1: Not available\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Cancer stage: Stage 4\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Mutation Count: 7.0\n",
      " * HER2 status: Yes\n",
      " * Gender: Female\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      "Question: \"What is the tumor purity of the sample?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: 30.0\n",
      " B: 10.0\n",
      " C: 50.0\n",
      " D: 60.0\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: C\n",
      "\n",
      "\n",
      "--- Prompt 6 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Gender: Female\n",
      " * History of PDL-1: Not available\n",
      " * HER2 status: Yes\n",
      " * Cancer stage: Stage 4\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Age of the patient: 34.0\n",
      " * Smoking history: Unknown\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * MSI Type: Stable\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Mutation Count: 7.0\n",
      " * Overal Survival Status: 1:DECEASED\n",
      "Question: \"Where did the cancer originally start in the body (Primary Tumor Site)?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: breast\n",
      " B: Pancreas\n",
      " C: Breast\n",
      " D: Transverse Colon\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: X\n",
      "\n",
      "\n",
      "--- Prompt 7 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Mutation Count: 7.0\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * MSI Type: Stable\n",
      " * Fraction Genome altered: 0.3578\n",
      " * History of PDL-1: Not available\n",
      " * HER2 status: Yes\n",
      " * Smoking history: Unknown\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Cancer stage: Stage 4\n",
      " * Age of the patient: 34.0\n",
      " * Gender: Female\n",
      "Question: \"Where has metastasis occurred in the body for this cancer patient?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: Bone, Intra Abdominal, Lymph Nodes\n",
      " B: Cns Brain, Intra Abdominal, Lung, Lymph Nodes\n",
      " C: Cns Brain, Intra Abdominal, Liver, Lung, Lymph Nodes, Pleura, Reproductive Organs\n",
      " D: Bone, Cns Brain, Intra Abdominal, Liver, Lymph Nodes\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: D\n",
      "\n",
      "\n",
      "--- Prompt 8 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * HER2 status: Yes\n",
      " * Smoking history: Unknown\n",
      " * Mutation Count: 7.0\n",
      " * Gender: Female\n",
      " * Cancer stage: Stage 4\n",
      " * MSI Type: Stable\n",
      " * History of PDL-1: Not available\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Age of the patient: 34.0\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Overal Survival Status: 1:DECEASED\n",
      "Question: \"How many months has the patient survived so far?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: 12.55889035\n",
      " B: 16.60272153\n",
      " C: 72.75608465\n",
      " D: 0.657533526\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: X\n",
      "\n",
      "\n",
      "--- Prompt 9 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Age of the patient: 34.0\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      " * Cancer stage: Stage 4\n",
      " * Smoking history: Unknown\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * Mutation Count: 7.0\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Gender: Female\n",
      " * MSI Type: Stable\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * History of PDL-1: Not available\n",
      " * HER2 status: Yes\n",
      "Question: \"What type of cancer did the patient have?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: Non-Small Cell Lung Cancer\n",
      " B: Prostate Cancer\n",
      " C: Breast Cancer\n",
      " D: Pancreatic Cancer\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: C\n",
      "\n",
      "\n",
      "--- Prompt 10 ---\n",
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter (A, B, C, or D).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Gender: Female\n",
      " * Fraction Genome altered: 0.3578\n",
      " * Age of the patient: 34.0\n",
      " * HER2 status: Yes\n",
      " * Overal Survival Status: 1:DECEASED\n",
      " * MSI Type: Stable\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Mutations history: CDKN2Ap14ARF, DICER1, JAK1, PAK7, CDKN2A, MLL2, PIK3CA\n",
      " * Mutation Count: 7.0\n",
      " * Smoking history: Unknown\n",
      " * Cancer stage: Stage 4\n",
      " * History of PDL-1: Not available\n",
      " * Treatment history: CARBOPLATIN, GEMCITABINE, EXEMESTANE, INVESTIGATIONAL, PACLITAXEL, LAPATINIB\n",
      "Question: \"What is the total number of non-synonymous mutations in the tumor tissue?\"\n",
      "Options (choose ONLY one option letter): \n",
      " A: 8.873242405\n",
      " B: 6.91758476\n",
      " C: 4.893598488\n",
      " D: 10.37637714\n",
      "\n",
      "    Answer:\n",
      "    \n",
      "Generated Answer: B\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (prompt_text, output) in enumerate(zip(X_val[:10], outputs[:10]), 1):\n",
    "    print(f\"--- Prompt {i} ---\")\n",
    "    print(prompt_text)\n",
    "    print(f\"Generated Answer: {output}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Infererence with Llama model: meta-llama/Llama-3-8-8B instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload model\n",
    "# MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# # Setup device\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# dtype = torch.float32  # MPS only supports float32\n",
    "\n",
    "# # Load model\n",
    "# llama_zero = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=dtype,\n",
    "#     device_map={\"\": device}\n",
    "# )\n",
    "# llama_zero.eval()\n",
    "\n",
    "# # Load tokenizer\n",
    "# tokenizer_llama = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "# tokenizer_llama.pad_token = tokenizer_llama.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_val.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_outputs(model, prompts, tokenizer, max_new_tokens=10):\n",
    "#     outputs = []\n",
    "\n",
    "#     for prompt_text in tqdm(prompts, desc=\"Generating answers\"):\n",
    "#         # Crea el mensaje estilo chat\n",
    "#         messages = [\n",
    "#             {\"role\": \"user\", \"content\": prompt_text}\n",
    "#         ]\n",
    "\n",
    "#         # Aplica el formato del modelo instruct\n",
    "#         formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "#         # Tokeniza y pasa a GPU o CPU\n",
    "#         inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "#         # Generación\n",
    "#         generated_ids = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=max_new_tokens,\n",
    "#             do_sample=True,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.9,\n",
    "#             pad_token_id=tokenizer.eos_token_id\n",
    "#         )\n",
    "\n",
    "#         # Extrae solo la respuesta generada\n",
    "#         generated_text = tokenizer.decode(\n",
    "#             generated_ids[0][inputs['input_ids'].shape[1]:],\n",
    "#             skip_special_tokens=True\n",
    "#         )\n",
    "#         print(f'inicio generated_text : {generated_text} fin')\n",
    "\n",
    "\n",
    "#         # Busca letra A–D como respuesta\n",
    "#         match = re.search(r'\\b([A-D])\\b', generated_text.strip().upper())\n",
    "#         outputs.append(match.group(1) if match else \"X\")\n",
    "\n",
    "#     return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = get_outputs(llama_zero, X_val[:20], tokenizer_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accu = get_accuracy(outputs, y_val[:20])\n",
    "# accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (prompt_text, output) in enumerate(zip(X_val[:10], outputs[:10]), 1):\n",
    "#     print(f\"--- Prompt {i} ---\")\n",
    "#     print(prompt_text)\n",
    "#     print(f\"Generated Answer: {output}\")\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model inference LLamma-3-8B\n",
    "# def get_outputs(model, prompts, tokenizer, max_new_tokens=2):\n",
    "\n",
    "#     outputs = []\n",
    "\n",
    "#     for i in tqdm(prompts, desc=\"Generating answers\"):\n",
    "#         tokenized_prompt = tokenizer(i, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "#         generated_ids = model.generate(\n",
    "#             input_ids=tokenized_prompt['input_ids'],\n",
    "#             attention_mask=tokenized_prompt['attention_mask'],\n",
    "#             max_new_tokens=max_new_tokens,\n",
    "#             do_sample=True,            # enable sampling\n",
    "#             temperature=0.7,           # controls randomness\n",
    "#             top_p=0.9,                 # nucleus sampling\n",
    "#             pad_token_id=tokenizer.eos_token_id\n",
    "#         )\n",
    "\n",
    "#         generated_text = tokenizer.decode(generated_ids[0][tokenized_prompt['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "#         # print(f'inicio generated_text : {generated_text} fin')\n",
    "\n",
    "#         match = re.search(r'\\b([A-D])\\b', generated_text.strip().upper())\n",
    "#         outputs.append(match.group(1) if match else \"X\")\n",
    "\n",
    "#     return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outputs = get_outputs(llama_zero, X_val[:2000], tokenizer_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: You are a helpful medical assistant. \n",
      "Based on the following patient data, answer the multiple-choice question by selecting the correct letter ([A], [B], [C], or [D]).\n",
      "Context: This is a cancer patient with the following characteristics:\n",
      " * Overal Survival Status: 0:LIVING\n",
      " * Cancer stage: Stage 1-3\n",
      " * Number of tumor diagnoses (ICD-O codes): 1\n",
      " * Fraction Genome altered: 0.1749\n",
      " * Gender: Female\n",
      " * Mutations history: CBFB, KMT2C, CDH1, ESR1\n",
      " * HER2 status: No\n",
      " * Mutation Count: 6.0\n",
      " * Smoking history: Never\n",
      " * History of PDL-1: Not available\n",
      " * MSI Type: Stable\n",
      " * Age of the patient: 77.0\n",
      " * Treatment history: INVESTIGATIONAL, LETROZOLE, INVESTIGATIONAL, PALBOCICLIB, PALBOCICLIB, INVESTIGATIONAL, INVESTIGATIONAL, INVESTIGATIONAL, CAPECITABINE, FULVESTRANT, INVESTIGATIONAL, OLAPARIB, SACITUZUMAB GOVITECAN, ELACESTRANT, DOXORUBICIN LIPOSOMAL, CARBOPLATIN\n",
      "Question: \"What are the metastatic sites located on the patient's body?\"\n",
      "Options (choose ONLY one option letter): \n",
      " [A]: Adrenal Glands, Bone, Lung, Lymph Nodes\n",
      " [B]: Bone, Intra Abdominal, Liver, Lung, Lymph Nodes, Reproductive Organs\n",
      " [C]: Adrenal Glands, Bone, Liver, Lung, Lymph Nodes, Reproductive Organs\n",
      " [D]: Adrenal Glands, Cns Brain, Lung, Lymph Nodes, Reproductive Organs\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infererence with Llama model: meta-llama/Llama-3-8-8B instruct - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= pickle.load(open('../../data/dataset-Prompts/datasets.pk', 'rb'))\n",
    "X_val = datasets['X_val']\n",
    "y_val = datasets['y_val']\n",
    "\n",
    "# Seed for reproducibility\n",
    "device =  'mps'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7777739e786147b387cfda8728ee383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a119d28dac6b40f9b606c885601afb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cecd6929d024eff86cd1da98b5ed3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc90618d9e134e058e5c7ded9618a186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa4477b661479781e50428377acd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3386\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3382\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3384\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3385\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3386\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3387\u001b[39m     )\n\u001b[32m   3389\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3390\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3440\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3437\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3438\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3439\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3440\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3441\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3442\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3444\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3445\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:1182\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:1053\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1050\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1059\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1060\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1069\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:861\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    854\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    859\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    860\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    866\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:746\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m    745\u001b[39m head = \u001b[38;5;28mself\u001b[39m.prepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m.long_header)\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m records = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    748\u001b[39m frames = []\n\u001b[32m    749\u001b[39m skipped = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:848\u001b[39m, in \u001b[36mVerboseTB.get_records\u001b[39m\u001b[34m(self, etb, context, tb_offset)\u001b[39m\n\u001b[32m    842\u001b[39m         FIs.append(\n\u001b[32m    843\u001b[39m             FrameInfo(\n\u001b[32m    844\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mRaw frame\u001b[39m\u001b[33m\"\u001b[39m, filename, lineno, frame, code, context=context\n\u001b[32m    845\u001b[39m             )\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FIs\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m res = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFrameInfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n\u001b[32m    849\u001b[39m res2 = [FrameInfo._from_stack_data_FrameInfo(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/core.py:597\u001b[39m, in \u001b[36mFrameInfo.stack_data\u001b[39m\u001b[34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[39m\n\u001b[32m    594\u001b[39m     frame, lineno = frame_and_lineno(x)\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m frame.f_code, lineno\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m collapse_repeated(\n\u001b[32m    598\u001b[39m     stack,\n\u001b[32m    599\u001b[39m     mapper=mapper,\n\u001b[32m    600\u001b[39m     collapser=RepeatedFrames,\n\u001b[32m    601\u001b[39m     key=_frame_key,\n\u001b[32m    602\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/utils.py:83\u001b[39m, in \u001b[36mcollapse_repeated\u001b[39m\u001b[34m(lst, collapser, mapper, key)\u001b[39m\n\u001b[32m     81\u001b[39m original_group, highlighted_group = \u001b[38;5;28mzip\u001b[39m(*group)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_highlighted:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(mapper, original_group)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     85\u001b[39m     keyed_group, _ = \u001b[38;5;28mzip\u001b[39m(*highlighted_group)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/core.py:587\u001b[39m, in \u001b[36mFrameInfo.stack_data.<locals>.mapper\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmapper\u001b[39m(f):\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/core.py:551\u001b[39m, in \u001b[36mFrameInfo.__init__\u001b[39m\u001b[34m(self, frame_or_tb, options)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    548\u001b[39m         frame_or_tb: Union[FrameType, TracebackType],\n\u001b[32m    549\u001b[39m         options: Optional[Options] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    550\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     \u001b[38;5;28mself\u001b[39m.executing = \u001b[43mSource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecuting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m     frame, \u001b[38;5;28mself\u001b[39m.lineno = frame_and_lineno(frame_or_tb)\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/executing/executing.py:264\u001b[39m, in \u001b[36mSource.executing\u001b[39m\u001b[34m(cls, frame_or_tb)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    263\u001b[39m     node = stmts = decorator = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     source = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfor_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m     tree = source.tree\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tree:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/executing/executing.py:183\u001b[39m, in \u001b[36mSource.for_frame\u001b[39m\u001b[34m(cls, frame, use_cache)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfor_frame\u001b[39m(\u001b[38;5;28mcls\u001b[39m, frame, use_cache=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# type: (types.FrameType, bool) -> \"Source\"\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    Returns the `Source` object corresponding to the file the frame is executing in.\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfor_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m.\u001b[49m\u001b[43mco_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/executing/executing.py:212\u001b[39m, in \u001b[36mSource.for_filename\u001b[39m\u001b[34m(cls, filename, module_globals, use_cache)\u001b[39m\n\u001b[32m    209\u001b[39m     linecache.cache[filename] = entry \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    210\u001b[39m     lines = get_lines()\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_for_filename_and_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/executing/executing.py:223\u001b[39m, in \u001b[36mSource._for_filename_and_lines\u001b[39m\u001b[34m(cls, filename, lines)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m result = source_cache[(filename, lines)] = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/executing/executing.py:163\u001b[39m, in \u001b[36mSource.__init__\u001b[39m\u001b[34m(self, filename, lines)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m._asttext = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: Optional[ASTText]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28mself\u001b[39m.tree = \u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSyntaxError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ast.py:54\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(source, filename, mode, type_comments, feature_version, optimize)\u001b[39m\n\u001b[32m     52\u001b[39m     feature_version = minor\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Else it should be an int giving the minor version for 3.x.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m               \u001b[49m\u001b[43m_feature_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "# model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct\"\n",
    "# model_id = \"google/medgemma-4b-it\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a helpful medical assistant. Based on the following patient data, answer the multiple-choice question by selecting onlh and only the correct letter ([A], [B], [C], or [D]).\"\n",
    "out = []\n",
    "for prompt_text in tqdm(X_val[:100]): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": prompt_text},\n",
    "    ]\n",
    "    \n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=20,\n",
    "        pad_token_id=128001\n",
    "    )\n",
    "    opt = '[X]'\n",
    "    for option in ['[A]', '[B]', '[C]', '[D]']:\n",
    "        if option in outputs[0][\"generated_text\"][-1]['content']:\n",
    "            opt = option\n",
    "    \n",
    "    out.append(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(out, y_val[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[C]': 32, '[D]': 27, '[X]': 18, '[B]': 16, '[A]': 7})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGEmma Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= pickle.load(open('../../data/dataset-Prompts/datasets.pk', 'rb'))\n",
    "X_val = datasets['X_val']\n",
    "y_val = datasets['y_val']\n",
    "\n",
    "# Seed for reproducibility\n",
    "device =  'mps'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435035a8afcd4378b7d32ad166363258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/931 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b1de922d854deeaf466625326fd8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb36f95cf28d429db548760980dbcfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef81efd3b3b42098c0f63c7f03fc629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c85543fd8f451aabfa463b2bea0e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00011.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9c45c27c144f1dbb6751b4c6930ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142bd79c13d84d12a1078e6dedbb2591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67b2fc3ed90425692f5b73485c175f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e307b6a9bfb458c958d42dbe2475c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89afb0c29a94d738cc683f5191880ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af334eda6ac410a824570d5e998308d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2025-07-05T01:42:43.540068Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/429826e75a6855c627678a8cbc48f88419fb16a9b174f2e5db8f539adb11bfc8?X-Xet-Signed-Range=bytes%3D0-66998988&Expires=1751683332&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80Mjk4MjZlNzVhNjg1NWM2Mjc2NzhhOGNiYzQ4Zjg4NDE5ZmIxNmE5YjE3NGYyZTVkYjhmNTM5YWRiMTFiZmM4P1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNjY5OTg5ODgiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzJ9fX1dfQ__&Signature=kGWJdjeZQDV-cIHdrhIAoXAj1EEWgMDwB1w3NllwX6Lm9Nf6PDvthxOISiFyLw~0rXft9dZtKAf4nD7TD9H4dWtc73Ch~3MqLpVeeMEdas1ErSnrrUT0b9LPkyKNwtXVxw24e2242UCgBbBd~WtZNDtWx93WXQo-76Ugkc2DLSts7BP6xmNOnmzOZcdcjePGJ-B1WOK7gfzt4KydjfSgjDhwppgGiAWZutty1dqaFrifnqsGBXzpYQyib4LJhwI~nvgVDnoy8CruNNGQFKt1j1niNWReqRAuz0FkX61xVsTFunCjK4CrNBbpd-JCVDEUXwADudT2W-wyVMh2~GL5EQ__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-05T01:42:43.544248Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 2.829898919s before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n",
      "{\"timestamp\":\"2025-07-05T01:42:45.448043Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/6da04b76af48878e241d8c2dae554bd599951a107746b8c67f53e1a8944549a3?X-Xet-Signed-Range=bytes%3D0-57521275&Expires=1751683332&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC82ZGEwNGI3NmFmNDg4NzhlMjQxZDhjMmRhZTU1NGJkNTk5OTUxYTEwNzc0NmI4YzY3ZjUzZTFhODk0NDU0OWEzP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTc1MjEyNzUiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzJ9fX1dfQ__&Signature=Ryfzj9Z2126GjByR-y9ikUktwBNtE4HMH5DvlDenHKpt-Cb~heQtVzBXveLXQLX7NFwDjqi9gjovN-Kt94HSD-Z276nRlqUAJBzaTAU-xdiX9~VaInQPs0TBPA9eEK4PHfu4w7dKfZV4gjXKKw~RG-8AVX-siTlurQj~eF~5DBtQCO9ZnfEwdiGsNewHrG0VRxZhA1B3RHcphjwCiQI48vmxTaUQXujo4g3J6tvb~bFqm96X~494vcA9344sNGV7oAoa~BaH8LhhkxzOt9z9vBSqLjy5M7l0u0PnrINtdKMHA9h21t5rfYyPWK3c~hz~X-oZ03JFkXPN3JmCMV7imA__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-05T01:42:45.448202Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 1.315000746s before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n",
      "{\"timestamp\":\"2025-07-05T01:42:46.658208Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/2a6588033a27d92df4de8b40eb0e8841b7fc927fc6fd72571d6595806e5c1851?X-Xet-Signed-Range=bytes%3D0-67101434&Expires=1751683334&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC8yYTY1ODgwMzNhMjdkOTJkZjRkZThiNDBlYjBlODg0MWI3ZmM5MjdmYzZmZDcyNTcxZDY1OTU4MDZlNWMxODUxP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNjcxMDE0MzQiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzR9fX1dfQ__&Signature=NRhuAcT2YZ8jHNI8KrgUc9h25xfvtlqf1Xid0p8bc1TsYfSjTt8XtdTO4Ixxh5TKQlzRfmveKvWfA0KVaek7mjvB~rJjlp68roTHjZGClkqmfBdvxhq4BEpZZpj~qf1pXDVhgKIqgnqhxSV0zKIAhjTg6r5bonO3RllSUROUPQx2DP0e9wW2ouJtrrTyCqQe4jPTmlUmugQGBhp-Z2hBPgg6hnOozK6HhquNuOUHdGfqu3V02-ZAnOXng1AaLH4uANRxVgErheVN3hpW2OGGKyOCO4Fzq-FCbF81N1W2kS5aUzVommuzoUyeJoFOf2nnECj9vlaN948hkAlaoEdn6Q__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-05T01:42:46.658389Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 950.070778ms before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n",
      "{\"timestamp\":\"2025-07-05T01:42:49.810476Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/fbfb3d834bbcb975878268365c841cc5446df9264dfd8fd64eb03c74f59953c3?X-Xet-Signed-Range=bytes%3D0-57488134&Expires=1751683339&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC9mYmZiM2Q4MzRiYmNiOTc1ODc4MjY4MzY1Yzg0MWNjNTQ0NmRmOTI2NGRmZDhmZDY0ZWIwM2M3NGY1OTk1M2MzP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTc0ODgxMzQiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzl9fX1dfQ__&Signature=Pxx4TWPuSDNg2uDwFuYaiHtOHgKEkh1v2YuGozPOuv1~Rjz4awaQzR~oeVGK2UGIn6wpgwvPJxpGBA8eNRoIx6Bmyzf03lLHHkTNmflb~RJ-s8MQOWfr3Hl4MhskXllcPoI4HRjqbiOeb9vAekbOMvgWT1BzqLdrseYJrjUWAFtcOSjdg7sgd7htP8GLdF62HyVG3vfNYLYjMKZcDRsF7QrpAIjjR1hCI7SJI7TDZKbOHSOCUb0tftLRU8A4Y7AUAihy32HqzQM-AElccgiXTZYV9TpZUDdbz7s3lApvrE2H38L~k25PA3m2uzYgxbt65xlUjZa9fk4awB2v2yGK4g__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-05T01:42:49.810553Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 2.326351265s before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n",
      "{\"timestamp\":\"2025-07-05T01:42:52.075014Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"error downloading range, error: ReqwestMiddlewareError(Middleware(error sending request for url (https://transfer.xethub.hf.co/xorbs/default/9a93b9eb2aaa432fdc6f8ed8b34a78099867bb8b2f976954ac1da0cb4263dbb0?X-Xet-Signed-Range=bytes%3D0-57483212&Expires=1751683338&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC85YTkzYjllYjJhYWE0MzJmZGM2ZjhlZDhiMzRhNzgwOTk4NjdiYjhiMmY5NzY5NTRhYzFkYTBjYjQyNjNkYmIwP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTc0ODMyMTIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzh9fX1dfQ__&Signature=q3KFP5mKlXwn3SQpr9CxxEdzuhjinEZNa7FHsJEuJq4gHnoDSRairL1-H4UyfaVmzWp5phRIGykwoeVbalm9Z5GoBmgLkSG1IjEQyz~X84TDWidx1iKe7erobIy-qpXHUKBJFtDDzxQhP6cFpPbWTlvLV6OhoRjP5BtDG8QVAGzCIcpyVIvop46i-kHVryl-h9uNN9irS9U42dXMFoC6XBTg65ZKlYjZiiMHcZq01zxcLGX6hQch04jS8L4GbIt-8e9z1w2edQItkjsrZjcR3qngG8T4xuJ6nRLERLB4-URTzjG6aqwHsrKqPKn3JJyyHDhMJGi0nrrpD0dIaxMR7A__&Key-Pair-Id=K2L8F4GPSG1IFC)\\n\\nCaused by:\\n    0: client error (SendRequest)\\n    1: channel closed))\",\"caller\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/download_utils.rs:528\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/error_printer/src/lib.rs\",\"line_number\":28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc24f4ea6922443cb43b37f6eb99ce87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00011.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2025-07-05T01:42:55.146614Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/795f14a7f21f0d7b7894434d1004161654f84205d2275f183c09c9955a0fb6d6?X-Xet-Signed-Range=bytes%3D0-58263798&Expires=1751683334&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC83OTVmMTRhN2YyMWYwZDdiNzg5NDQzNGQxMDA0MTYxNjU0Zjg0MjA1ZDIyNzVmMTgzYzA5Yzk5NTVhMGZiNmQ2P1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTgyNjM3OTgiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTE2ODMzMzR9fX1dfQ__&Signature=dDbsiLVWkOK4upiC~Yyd16fEMu5FJMWtSTesMNbXHxYiUPKBYl0axinn1ttZy-tJun9vQ7G2l66q-WOYr8Yr4VeJB9dq18s5ZL0Iz0OVBpFjxJCj5YCMfo5yszD3m-Bm20BdG1EKcYBSqRBQbfKZPGPL7a1VvfpDnsX1jpYJD5EVMnyS9L1yhcyF08L2Mx6AhuUXYSf~9k-8SwTyqXJ~NBT0mjfzRAb55Nl9-rvHjjiZxo7NKrzri-gQ5HhoGNqJM0BDSiTGPmb6ZJ~QVtvpALEax6SyScZaZ53uV3NdMhWcDOjC2hz-6148hk2yop~90GRPCfhvVfkHmsSciPv9aA__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-05T01:42:55.146756Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 1.385363252s before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3386\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3382\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3384\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3385\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3386\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3387\u001b[39m     )\n\u001b[32m   3389\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3390\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3440\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3437\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3438\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3439\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3440\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3441\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3442\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3444\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3445\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:1182\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:1053\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1050\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1059\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1060\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1069\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:889\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    887\u001b[39m chained_exc_ids = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m    888\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m evalue:\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m     formatted_exceptions += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m     exception = \u001b[38;5;28mself\u001b[39m.get_parts_of_chained_exception(evalue)\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mid\u001b[39m(exception[\u001b[32m1\u001b[39m]) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chained_exc_ids:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:773\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    763\u001b[39m         frames.append(\n\u001b[32m    764\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    765\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m             )\n\u001b[32m    771\u001b[39m         )\n\u001b[32m    772\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    775\u001b[39m     frames.append(\n\u001b[32m    776\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    777\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/ultratb.py:651\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/IPython/core/tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/stack_data/utils.py:164\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    161\u001b[39m             length += \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ttype, value\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m lexer = \u001b[43mMyLexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripnl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    166\u001b[39m     highlighted = pygments.highlight(code, lexer, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:660\u001b[39m, in \u001b[36mRegexLexerMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwds)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28mcls\u001b[39m._tokens = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_tokendef\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokendefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m.\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:599\u001b[39m, in \u001b[36mRegexLexerMeta.process_tokendef\u001b[39m\u001b[34m(cls, name, tokendefs)\u001b[39m\n\u001b[32m    597\u001b[39m tokendefs = tokendefs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokens[name]\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokendefs):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokendefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:579\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tdef) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwrong rule def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     rex = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muncompilable regex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:507\u001b[39m, in \u001b[36mRegexLexerMeta._process_regex\u001b[39m\u001b[34m(cls, regex, rflags, state)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Preprocess the regular expression component of a token definition.\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(regex, Future):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     regex = \u001b[43mregex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m re.compile(regex, rflags).match\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/lexer.py:495\u001b[39m, in \u001b[36mwords.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregex_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:91\u001b[39m, in \u001b[36mregex_opt\u001b[39m\u001b[34m(strings, prefix, suffix)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a compiled regex that matches any string in the given list.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;03mThe strings to match must be literal strings, not regexes.  They will be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m*prefix* and *suffix* are pre- and appended to the final regex.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     90\u001b[39m strings = \u001b[38;5;28msorted\u001b[39m(strings)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prefix + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m + suffix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:63\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# we have a prefix for all strings\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# print '-> prefix:', prefix\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + escape(prefix) \\\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplen\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     64\u001b[39m         + close_paren\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# is there a suffix?\u001b[39;00m\n\u001b[32m     66\u001b[39m strings_rev = [s[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:72\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     69\u001b[39m     slen = \u001b[38;5;28mlen\u001b[39m(suffix)\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# print '-> suffix:', suffix[::-1]\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[43mslen\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m     77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(regex_opt_inner(\u001b[38;5;28mlist\u001b[39m(group[\u001b[32m1\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:63\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# we have a prefix for all strings\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# print '-> prefix:', prefix\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + escape(prefix) \\\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplen\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     64\u001b[39m         + close_paren\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# is there a suffix?\u001b[39;00m\n\u001b[32m     66\u001b[39m strings_rev = [s[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "    \u001b[31m[... skipping similar frames: <genexpr> at line 77 (2 times), regex_opt_inner at line 77 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/data/environments/intern_summer2025/lib/python3.13/site-packages/pygments/regexopt.py:36\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     33\u001b[39m first = strings[\u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(strings) == \u001b[32m1\u001b[39m:\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# print '-> only 1 string'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \u001b[43mescape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m)\u001b[49m + close_paren\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# print '-> first string empty'\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + regex_opt_inner(strings[\u001b[32m1\u001b[39m:], \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     40\u001b[39m         + \u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/re/__init__.py:310\u001b[39m, in \u001b[36mescape\u001b[39m\u001b[34m(pattern)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[33;03mEscape special characters in a string.\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pattern, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpattern\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_special_chars_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    312\u001b[39m     pattern = \u001b[38;5;28mstr\u001b[39m(pattern, \u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "# model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct\"\n",
    "# model_id = \"google/medgemma-4b-it\"\n",
    "model_id = \"google/medgemma-27b-text-it\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 100/100 [01:30<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a helpful medical assistant. Based on the following patient data, answer the multiple-choice question by selecting onlh and only the correct letter ([A], [B], [C], or [D]).\"\n",
    "out = []\n",
    "for prompt_text in tqdm(X_val[:100]): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": system}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt_text}]},\n",
    "    ]\n",
    "    \n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=20,\n",
    "        # pad_token_id=128001\n",
    "    )\n",
    "    opt = '[X]'\n",
    "    for option in ['[A]', '[B]', '[C]', '[D]']:\n",
    "        if option in outputs[0][\"generated_text\"][-1]['content']:\n",
    "            opt = option\n",
    "    \n",
    "    out.append(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(out, y_val[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[A]': 47, '[B]': 19, '[C]': 18, '[D]': 16})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from typing import List, Dict\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '' \n",
    "os.environ['GEMINI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a helpful medical assistant. Based on the following patient data, answer the multiple-choice question by selecting onlh and only the correct letter ([A], [B], [C], or [D]).\"\n",
    "class Output(BaseModel):\n",
    "    answer: str = Field(description=\"returns the answer to the questions as one of: [A], [B], [C] or [D]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    'gemini-2.5-flash',\n",
    "    # 'openai:gpt-4.1-nano-2025-04-14',\n",
    "    # 'openai:gpt-4.1-mini-2025-04-14',\n",
    "    # 'openai:gpt-4.1',\n",
    "    system_prompt=system,\n",
    "    output_type=Output,\n",
    "    Instrument=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 100/100 [21:14<00:00, 12.74s/it]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for prompt_text in tqdm(X_val[:100]): \n",
    "    result = await agent.run(prompt_text)\n",
    "    out.append(result.output.answer)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [f'[{i}]' if not '[' in i else i for i in out ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(out, y_val[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on the 100 first questions: \n",
    "\n",
    "* GPT4.1-nano: 0.5\n",
    "* GPT4.1-mini: 0.56\n",
    "* GPT4.1: 0.64\n",
    "* Llama-3-8B-Instruct: 0.35\n",
    "* Llama-3.2-1B-Instruct: 0.43\n",
    "* Llama-3.2-3B-Instruct: 0.47\n",
    "* Gemini-2.5-flash: 0.64\n",
    "* medgemma-4b-it: 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.52.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.52.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOjmKESM64T0hKdPNrCRWN2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0088ee3ff026403eb87fa3d85bcc0d46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b35977e47de46abb1d4b0e15223dd0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10b5949425654b49ad3d08539550ad28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd14e972616417ca3b06cd40b8606de",
      "placeholder": "​",
      "style": "IPY_MODEL_449f3e5a5b0e4ef2b4cd9e7e68b1eafa",
      "value": "generation_config.json: 100%"
     }
    },
    "10ec2adc23af474ca9880c4f0c09ce75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0088ee3ff026403eb87fa3d85bcc0d46",
      "placeholder": "​",
      "style": "IPY_MODEL_53931ab3cea84233b9da2deae18e498a",
      "value": " 50.5k/50.5k [00:00&lt;00:00, 1.31MB/s]"
     }
    },
    "14684c09fa9248a6acad9e1abdf844f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a31e3dda0c84a5f90cec66ccba14a82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "202eb6aadec746dda0f09abf4e52260d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ab1c31382ba405eb5473b390d5b61d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3025a7a3bc0641fe9d82b1787c35669f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "303bb2ef644446bdb0d042a942521acb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3baa5548f46f4e94a5a0910cc7d6e17f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e74c67a009648d0b70d5b0cb18a4d4c",
      "max": 2471645608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3ebbb828cbd484696f39de4d62a0843",
      "value": 2471645608
     }
    },
    "43fab6d9e1fb43ed9b6fc27deac10a52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "449f3e5a5b0e4ef2b4cd9e7e68b1eafa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4875446e019e45ab9458f92c393c6374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3435f4c90f14c808b57ed74e50908d2",
       "IPY_MODEL_63f0fc7942124b68b82acb9683c0c820",
       "IPY_MODEL_579b355e3c8e43609f7bcaf03a2a179e"
      ],
      "layout": "IPY_MODEL_d9404c11710442388654b71cd506803d"
     }
    },
    "48a602a4bbfd497cb44daf3d5e7ec45e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "492b5f09429a466ea8c7e7d2e7ce8693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "497af44c69ac4c44bc4903f51edf59ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cecfabca8534e2cb7708986ab526c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d00428af1f843599c9f8f284189f416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbe62fd9f89647858f5b4cc95fa467a6",
       "IPY_MODEL_3baa5548f46f4e94a5a0910cc7d6e17f",
       "IPY_MODEL_cec2105aaa2e41cbaff01045e553cbd2"
      ],
      "layout": "IPY_MODEL_ed5f40d0db704f6e9fb89028cd5f325a"
     }
    },
    "4d8665ef790f4afba981f2344a82e3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43fab6d9e1fb43ed9b6fc27deac10a52",
      "max": 50500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14684c09fa9248a6acad9e1abdf844f8",
      "value": 50500
     }
    },
    "53931ab3cea84233b9da2deae18e498a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "579b355e3c8e43609f7bcaf03a2a179e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72c3a5e1a1d54496acc73ded71117e69",
      "placeholder": "​",
      "style": "IPY_MODEL_202eb6aadec746dda0f09abf4e52260d",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 21.9MB/s]"
     }
    },
    "623c81a441384000b60f70d8c1a0a795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cecfabca8534e2cb7708986ab526c4a",
      "max": 301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ab1c31382ba405eb5473b390d5b61d2",
      "value": 301
     }
    },
    "63f0fc7942124b68b82acb9683c0c820": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_303bb2ef644446bdb0d042a942521acb",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b6147fd0fe2c44c085d7850b28313ecd",
      "value": 9085657
     }
    },
    "67bef14fa2e84f3b837e5787d151c3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69f90315a47c4c859dd3b1ba13a63482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_adbf90264e114f8a8d2a68b7b22dff28",
       "IPY_MODEL_4d8665ef790f4afba981f2344a82e3f1",
       "IPY_MODEL_10ec2adc23af474ca9880c4f0c09ce75"
      ],
      "layout": "IPY_MODEL_ec6335de6cff41e2a316093a54c96f7a"
     }
    },
    "6e404feda7f04b8391ffe6fcd6d97f92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e74c67a009648d0b70d5b0cb18a4d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c3a5e1a1d54496acc73ded71117e69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72f84c8e08c04094a2b27cf938ecad4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7379fe55ed244828ba6cc895220d4f09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75d615e176aa46b5a5bedf2dc48da75a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78405dbff41e46a6ad9541228c2035fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7379fe55ed244828ba6cc895220d4f09",
      "max": 843,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bdc2bc1767f8402b8f8148e7bc4467e8",
      "value": 843
     }
    },
    "80e8618a393c447596704f74e1c2ca23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9612d26ad3d145cd8bcc08a5a3859914",
      "placeholder": "​",
      "style": "IPY_MODEL_492b5f09429a466ea8c7e7d2e7ce8693",
      "value": " 185/185 [00:00&lt;00:00, 4.63kB/s]"
     }
    },
    "8485e8a28f264e12a282d09577e421e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "876ed0f3244f4ee6aec97dea09941cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5e50f61d2024c09a6dff1c778c0c95b",
      "placeholder": "​",
      "style": "IPY_MODEL_67bef14fa2e84f3b837e5787d151c3c5",
      "value": "config.json: 100%"
     }
    },
    "88a5222bc7444312b1f1a56c76fe1bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_876ed0f3244f4ee6aec97dea09941cce",
       "IPY_MODEL_78405dbff41e46a6ad9541228c2035fe",
       "IPY_MODEL_8bdec4c7248d43258864f7f4fd691f36"
      ],
      "layout": "IPY_MODEL_1a31e3dda0c84a5f90cec66ccba14a82"
     }
    },
    "8b07f1caca2949668734b419b8a6c945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca585ec7b4a94176b20d4bd0ce044a4d",
      "max": 185,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b35977e47de46abb1d4b0e15223dd0d",
      "value": 185
     }
    },
    "8bdec4c7248d43258864f7f4fd691f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3025a7a3bc0641fe9d82b1787c35669f",
      "placeholder": "​",
      "style": "IPY_MODEL_6e404feda7f04b8391ffe6fcd6d97f92",
      "value": " 843/843 [00:00&lt;00:00, 19.6kB/s]"
     }
    },
    "9612d26ad3d145cd8bcc08a5a3859914": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1e47436c4d4db39f1de0d93a70c256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a64ca0bc051e460486eee54477d60e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a86d675647714cb794e9be32e240b4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adbf90264e114f8a8d2a68b7b22dff28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7ea70e72e7a449eaeec4133c5ef2b40",
      "placeholder": "​",
      "style": "IPY_MODEL_e2bb8e01b4fd440c89ad6bb975392afe",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ae5b6f2f15754660b12dc9fd9d7ddf88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b420185cfaba440d9f7f3f87d9819237": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6147fd0fe2c44c085d7850b28313ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bbe62fd9f89647858f5b4cc95fa467a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8485e8a28f264e12a282d09577e421e6",
      "placeholder": "​",
      "style": "IPY_MODEL_72f84c8e08c04094a2b27cf938ecad4d",
      "value": "model.safetensors: 100%"
     }
    },
    "bdc2bc1767f8402b8f8148e7bc4467e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c08eabcc5a5f46e5b667917a48ce925b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7ea70e72e7a449eaeec4133c5ef2b40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8ad1a52c0f14017b2b170337024fb0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_497af44c69ac4c44bc4903f51edf59ad",
      "placeholder": "​",
      "style": "IPY_MODEL_75d615e176aa46b5a5bedf2dc48da75a",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "ca585ec7b4a94176b20d4bd0ce044a4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdb4979630224e6ba3d4411f0f8d32dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0e7eb30cb3745ab907ce0b9425aa469",
      "placeholder": "​",
      "style": "IPY_MODEL_a64ca0bc051e460486eee54477d60e5c",
      "value": " 301/301 [00:00&lt;00:00, 5.88kB/s]"
     }
    },
    "cec2105aaa2e41cbaff01045e553cbd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b420185cfaba440d9f7f3f87d9819237",
      "placeholder": "​",
      "style": "IPY_MODEL_9e1e47436c4d4db39f1de0d93a70c256",
      "value": " 2.47G/2.47G [01:03&lt;00:00, 129MB/s]"
     }
    },
    "d5e50f61d2024c09a6dff1c778c0c95b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8ec60aee5684d81a250fefcc8be0745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8ad1a52c0f14017b2b170337024fb0a",
       "IPY_MODEL_623c81a441384000b60f70d8c1a0a795",
       "IPY_MODEL_cdb4979630224e6ba3d4411f0f8d32dd"
      ],
      "layout": "IPY_MODEL_a86d675647714cb794e9be32e240b4f7"
     }
    },
    "d9404c11710442388654b71cd506803d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de2c365f404f40d0914b32b0a70a3ff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10b5949425654b49ad3d08539550ad28",
       "IPY_MODEL_8b07f1caca2949668734b419b8a6c945",
       "IPY_MODEL_80e8618a393c447596704f74e1c2ca23"
      ],
      "layout": "IPY_MODEL_ae5b6f2f15754660b12dc9fd9d7ddf88"
     }
    },
    "e0e7eb30cb3745ab907ce0b9425aa469": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2bb8e01b4fd440c89ad6bb975392afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3435f4c90f14c808b57ed74e50908d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c08eabcc5a5f46e5b667917a48ce925b",
      "placeholder": "​",
      "style": "IPY_MODEL_48a602a4bbfd497cb44daf3d5e7ec45e",
      "value": "tokenizer.json: 100%"
     }
    },
    "ec6335de6cff41e2a316093a54c96f7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed5f40d0db704f6e9fb89028cd5f325a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efd14e972616417ca3b06cd40b8606de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3ebbb828cbd484696f39de4d62a0843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
